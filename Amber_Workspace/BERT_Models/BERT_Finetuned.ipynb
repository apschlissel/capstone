{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kLB3I4FKZ5Lr",
    "tags": []
   },
   "source": [
    "# Fine-tuning BERT (and friends) for multi-label text classification\n",
    "\n",
    "In this notebook, we are going to fine-tune BERT to predict one or more labels for a given piece of text. Note that this notebook illustrates how to fine-tune a bert-base-uncased model, but you can also fine-tune a RoBERTa, DeBERTa, DistilBERT, CANINE, ... checkpoint in the same way. \n",
    "\n",
    "All of those work in the same way: they add a linear layer on top of the base model, which is used to produce a tensor of shape (batch_size, num_labels), indicating the unnormalized scores for a number of labels for every example in the batch.\n",
    "\n",
    "\n",
    "\n",
    "## Set-up environment\n",
    "\n",
    "First, we install the libraries which we'll use: HuggingFace Transformers and Datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "4wxY3x-ZZz8h"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-27 12:33:40.058717: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2022-07-27 12:33:40.063159: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-07-27 12:33:40.063173: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "import s3fs\n",
    "import boto3\n",
    "import pandas as pd\n",
    "import nltk\n",
    "\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.corpus import wordnet\n",
    "from nltk.tokenize import word_tokenize\n",
    "import tensorflow as tf\n",
    "import transformers\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bIH9NP0MZ6-O"
   },
   "source": [
    "## Load dataset\n",
    "\n",
    "Next, let's download a multi-label text classification dataset from the [hub](https://huggingface.co/).\n",
    "\n",
    "At the time of writing, I picked a random one as follows:   \n",
    "\n",
    "* first, go to the \"datasets\" tab on huggingface.co\n",
    "* next, select the \"multi-label-classification\" tag on the left as well as the the \"1k<10k\" tag (fo find a relatively small dataset).\n",
    "\n",
    "Note that you can also easily load your local data (i.e. csv files, txt files, Parquet files, JSON, ...) as explained [here](https://huggingface.co/docs/datasets/loading.html#local-and-remote-files).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv('BERTopic_Labeled.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      ['wall', 'street', 'journal', 'amazon', 'bests...\n",
       "1      ['helping', 'set', 'stage', 'biowares', 'hotly...\n",
       "2      ['sebastian', 'locke', 'fiftysixyearold', 'pat...\n",
       "3      ['take', 'back', 'oxmoon', 'lost', 'paradise',...\n",
       "4      ['mayflower', 'set', 'sail', 'carried', 'board...\n",
       "                             ...                        \n",
       "995    ['lee', 'wants', 'tarantula', 'member', 'bigge...\n",
       "996    ['merry', 'adventures', 'robin', 'hood', 'grea...\n",
       "997    ['moving', 'presentday', 'oslo', 'brooklyn', '...\n",
       "998    ['captivating', 'sequel', 'inkheart', 'critica...\n",
       "999    ['santa', 'claus', 'dear', 'old', 'friend', 't...\n",
       "Name: tokens, Length: 1000, dtype: object"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['tokens']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_string(text):\n",
    "    text_preprocessed = (\" \").join(text)\n",
    "    return text_preprocessed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ast import literal_eval\n",
    "dataset['tokens'] = dataset['tokens'].apply(lambda row: literal_eval(row))\n",
    "dataset['tokens'] = dataset['tokens'].apply(lambda x: make_string(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.rename(columns = {'Unnamed: 0':'ID'}, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset[['ID','description', 'university', 'relationships', 'break ups', 'divorce', 'weddings', 'death', 'family', 'friendship']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>description</th>\n",
       "      <th>university</th>\n",
       "      <th>relationships</th>\n",
       "      <th>break ups</th>\n",
       "      <th>divorce</th>\n",
       "      <th>weddings</th>\n",
       "      <th>death</th>\n",
       "      <th>family</th>\n",
       "      <th>friendship</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>39,822</td>\n",
       "      <td>From the Wall Street Journal and #1 Amazon bes...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>34,235</td>\n",
       "      <td>Helping set the stage for BioWare's hotly anti...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>27,904</td>\n",
       "      <td>Sebastian Locke, the fifty-six-year-old patria...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10,515</td>\n",
       "      <td>\"Take me back to Oxmoon, the lost paradise of ...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>935</td>\n",
       "      <td>When the Mayflower set sail in 1620, it carrie...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>17,361</td>\n",
       "      <td>Lee wants to be a Tarantula â€“ a member of the ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>9,029</td>\n",
       "      <td>The Merry Adventures of Robin Hood of Great Re...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>32,216</td>\n",
       "      <td>Moving from present-day Oslo to Brooklyn in th...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>1,036</td>\n",
       "      <td>The captivating sequel to INKHEART, the critic...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>9,738.00</td>\n",
       "      <td>Santa Claus, my dear old friend, you are a thi...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows Ã— 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           ID                                        description university  \\\n",
       "0      39,822  From the Wall Street Journal and #1 Amazon bes...      False   \n",
       "1      34,235  Helping set the stage for BioWare's hotly anti...      False   \n",
       "2      27,904  Sebastian Locke, the fifty-six-year-old patria...      False   \n",
       "3      10,515  \"Take me back to Oxmoon, the lost paradise of ...      False   \n",
       "4         935  When the Mayflower set sail in 1620, it carrie...      False   \n",
       "..        ...                                                ...        ...   \n",
       "995    17,361  Lee wants to be a Tarantula â€“ a member of the ...        NaN   \n",
       "996     9,029  The Merry Adventures of Robin Hood of Great Re...        NaN   \n",
       "997    32,216  Moving from present-day Oslo to Brooklyn in th...        NaN   \n",
       "998     1,036  The captivating sequel to INKHEART, the critic...        NaN   \n",
       "999  9,738.00  Santa Claus, my dear old friend, you are a thi...        NaN   \n",
       "\n",
       "    relationships break ups divorce weddings  death family friendship  \n",
       "0            True     False   False    False  False  False      False  \n",
       "1           False     False   False    False  False  False      False  \n",
       "2            True     False    True    False   True   True      False  \n",
       "3            True     False   False    False  False   True      False  \n",
       "4           False     False   False    False  False  False      False  \n",
       "..            ...       ...     ...      ...    ...    ...        ...  \n",
       "995           NaN       NaN     NaN      NaN    NaN    NaN       True  \n",
       "996           NaN       NaN     NaN      NaN    NaN    NaN        NaN  \n",
       "997           NaN       NaN     NaN      NaN    NaN   True        NaN  \n",
       "998           NaN       NaN     NaN      NaN    NaN    NaN        NaN  \n",
       "999           NaN       NaN     NaN      NaN    NaN   True       True  \n",
       "\n",
       "[1000 rows x 10 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.replace(np.nan, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset[0:699].to_csv('dataset_bert_train.csv')\n",
    "dataset[700:899].to_csv('dataset_bert_test.csv')\n",
    "dataset[900:999].to_csv('dataset_bert_validation.csv')\n",
    "dataset[700:999].to_csv('dataset_bert_test_val.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QCL02vQgxYTO"
   },
   "source": [
    "As we can see, the dataset contains 3 splits: one for training, one for validation and one for testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-2e8fb01ee019b551\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset csv/default to /home/ec2-user/.cache/huggingface/datasets/csv/default-2e8fb01ee019b551/0.0.0/51cce309a08df9c4d82ffd9363bbe090bf173197fc01a71b034e8594995a1a58...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f0bae39910414328ba7e9107187104f5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data files:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f856befd021d40d7bef517f41ec1fbf3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting data files:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0 tables [00:00, ? tables/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0 tables [00:00, ? tables/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0 tables [00:00, ? tables/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset csv downloaded and prepared to /home/ec2-user/.cache/huggingface/datasets/csv/default-2e8fb01ee019b551/0.0.0/51cce309a08df9c4d82ffd9363bbe090bf173197fc01a71b034e8594995a1a58. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8829929e2b6048c686e2e6a5c78f3aef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "dataset = load_dataset('csv', data_files={'train': ['dataset_bert_train.csv'], 'test': 'dataset_bert_test.csv', 'validation':'dataset_bert_validation.csv'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PgS0wMWExcqP"
   },
   "source": [
    "Let's check the first example of the training split:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "unjuTtKUjZI3",
    "outputId": "6f1e5051-8272-40f9-ced8-ba17a105e904"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Unnamed: 0': 0,\n",
       " 'ID': '39,822',\n",
       " 'description': 'From the Wall Street Journal and #1 Amazon bestselling author comes a new installment to the Blue Moon small town romance series.  A womanizing bad boy with a motorcycle and sexy-as-sin smile is not part of Emmaâ€™s life plan.  She moved cross-country to be close to family and finally settle down in hippie, trippy, nosey Blue Moon Bend. But when famed fashion photographer Niko shows up with his leather jacket, underwear-melting voice, and a problem, she sees nothing but trouble.  Heâ€™s all wrong for Emma, but that doesnâ€™t stop the attraction from boiling over.  Niko doesnâ€™t let being friend zoned get in his way. Once he gets his handsâ€”and his mouthâ€”on her, will their friendship survive? Or will he lose everything heâ€™s worked for back in New York to the redhead who dominates his every thought? ',\n",
       " 'university': False,\n",
       " 'relationships': True,\n",
       " 'break ups': False,\n",
       " 'divorce': False,\n",
       " 'weddings': False,\n",
       " 'death': False,\n",
       " 'family': False,\n",
       " 'friendship': False}"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example = dataset['train'][0]\n",
    "example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6DV0Rtetxgd4"
   },
   "source": [
    "The dataset consists of tweets, labeled with one or more emotions. \n",
    "\n",
    "Let's create a list that contains the labels, as well as 2 dictionaries that map labels to integers and back."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "e5vZhQpvkE8s",
    "outputId": "5d513b30-f209-492f-c6ab-245d64a67d40"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['university',\n",
       " 'relationships',\n",
       " 'break ups',\n",
       " 'divorce',\n",
       " 'weddings',\n",
       " 'death',\n",
       " 'family',\n",
       " 'friendship']"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = [label for label in dataset['train'][0].keys() if label not in ['ID', 'description', 'Unnamed: 0']]\n",
    "id2label = {idx:label for idx, label in enumerate(labels)}\n",
    "label2id = {label:idx for idx, label in enumerate(labels)}\n",
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['Unnamed: 0', 'ID', 'description', 'university', 'relationships', 'break ups', 'divorce', 'weddings', 'death', 'family', 'friendship'],\n",
       "        num_rows: 699\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['Unnamed: 0', 'ID', 'description', 'university', 'relationships', 'break ups', 'divorce', 'weddings', 'death', 'family', 'friendship'],\n",
       "        num_rows: 199\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['Unnamed: 0', 'ID', 'description', 'university', 'relationships', 'break ups', 'divorce', 'weddings', 'death', 'family', 'friendship'],\n",
       "        num_rows: 99\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nJ3Teyjmank2"
   },
   "source": [
    "## Preprocess data\n",
    "\n",
    "As models like BERT don't expect text as direct input, but rather `input_ids`, etc., we tokenize the text using the tokenizer. Here I'm using the `AutoTokenizer` API, which will automatically load the appropriate tokenizer based on the checkpoint on the hub.\n",
    "\n",
    "What's a bit tricky is that we also need to provide labels to the model. For multi-label text classification, this is a matrix of shape (batch_size, num_labels). Also important: this should be a tensor of floats rather than integers, otherwise PyTorch' `BCEWithLogitsLoss` (which the model will use) will complain, as explained [here](https://discuss.pytorch.org/t/multi-label-binary-classification-result-type-float-cant-be-cast-to-the-desired-output-type-long/117915/3)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "id": "AFWlSsbZaRLc"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file https://huggingface.co/bert-base-uncased/resolve/main/config.json from cache at /home/ec2-user/.cache/huggingface/transformers/3c61d016573b14f7f008c02c4e51a366c67ab274726fe2910691e2a761acf43e.37395cee442ab11005bcd270f3c34464dc1704b715b5d7d52b1a461abe3b9e4e\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"bert-base-uncased\",\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.20.1\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading file https://huggingface.co/bert-base-uncased/resolve/main/vocab.txt from cache at /home/ec2-user/.cache/huggingface/transformers/45c3f7a79a80e1cf0a489e5c62b43f173c15db47864303a55d623bb3c96f72a5.d789d64ebfe299b0e416afc4a169632f903f693095b4629a7ea271d5a0cf2c99\n",
      "loading file https://huggingface.co/bert-base-uncased/resolve/main/tokenizer.json from cache at /home/ec2-user/.cache/huggingface/transformers/534479488c54aeaf9c3406f647aa2ec13648c06771ffe269edabebd4c412da1d.7f2721073f19841be16f41b0a70b600ca6b880c8f3df6f3535cbc704371bdfa4\n",
      "loading file https://huggingface.co/bert-base-uncased/resolve/main/added_tokens.json from cache at None\n",
      "loading file https://huggingface.co/bert-base-uncased/resolve/main/special_tokens_map.json from cache at None\n",
      "loading file https://huggingface.co/bert-base-uncased/resolve/main/tokenizer_config.json from cache at /home/ec2-user/.cache/huggingface/transformers/c1d7f0a763fb63861cc08553866f1fc3e5a6f4f07621be277452d26d71303b7e.20430bd8e10ef77a7d2977accefe796051e01bc2fc4aa146bc862997a1a15e79\n",
      "loading configuration file https://huggingface.co/bert-base-uncased/resolve/main/config.json from cache at /home/ec2-user/.cache/huggingface/transformers/3c61d016573b14f7f008c02c4e51a366c67ab274726fe2910691e2a761acf43e.37395cee442ab11005bcd270f3c34464dc1704b715b5d7d52b1a461abe3b9e4e\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"bert-base-uncased\",\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.20.1\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "import numpy as np\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "\n",
    "def preprocess_data(examples):\n",
    "  # take a batch of texts\n",
    "  text = examples['description']\n",
    "  # encode them\n",
    "  encoding = tokenizer(text, padding=\"max_length\", truncation=True, max_length=128)\n",
    "  # add labels\n",
    "  labels_batch = {k: examples[k] for k in examples.keys() if k in labels}\n",
    "  # create numpy array of shape (batch_size, num_labels)\n",
    "  labels_matrix = np.zeros((len(text), len(labels)))\n",
    "  # fill numpy array\n",
    "  for idx, label in enumerate(labels):\n",
    "    labels_matrix[:, idx] = labels_batch[label]\n",
    "\n",
    "  encoding[\"labels\"] = labels_matrix.tolist()\n",
    "  \n",
    "  return encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "i4ENBTdulBEI",
    "outputId": "02554a1f-4961-461a-bf29-555b8debeabf"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "39cc7fd5421d445880ce8f1e84f48925",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1bc7bb04920447538beab4f53ad38c86",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fd8ca61596bb4c988676a0295810bcca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "encoded_dataset = dataset.map(preprocess_data, batched=True, remove_columns=dataset['train'].column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0enAb0W9o25W",
    "outputId": "55bc5ba6-d169-49c6-f562-bb7ea4143866"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'labels'])\n"
     ]
    }
   ],
   "source": [
    "example = encoded_dataset['train'][0]\n",
    "print(example.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 137
    },
    "id": "D0McCtJ8HRJY",
    "outputId": "82fb0336-51a3-40ad-ebc0-65eeb7cf4b6c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[CLS] from the wall street journal and # 1 amazon bestselling author comes a new installment to the blue moon small town romance series. a womanizing bad boy with a motorcycle and sexy - as - sin smile is not part of emma â€™ s life plan. she moved cross - country to be close to family and finally settle down in hippie, trippy, nosey blue moon bend. but when famed fashion photographer niko shows up with his leather jacket, underwear - melting voice, and a problem, she sees nothing but trouble. he â€™ s all wrong for emma, but that doesn â€™ t stop the attraction from boiling over [SEP]'"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(example['input_ids'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VdIvj6WjHeZQ",
    "outputId": "418c14d2-cca3-44e9-d0a2-6ad4ca7a007c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example['labels']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "q4Dx95t2o6N9",
    "outputId": "3ce6c923-0b45-4743-bc4b-7771d088b03e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['relationships']"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[id2label[idx] for idx, label in enumerate(example['labels']) if label == 1.0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HgpKXDfvKBxn"
   },
   "source": [
    "Finally, we set the format of our data to PyTorch tensors. This will turn the training, validation and test sets into standard PyTorch [datasets](https://pytorch.org/docs/stable/data.html). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "id": "Lk6Cq9duKBkA"
   },
   "outputs": [],
   "source": [
    "encoded_dataset.set_format(\"torch\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "w5qSmCgWefWs"
   },
   "source": [
    "## Define model\n",
    "\n",
    "Here we define a model that includes a pre-trained base (i.e. the weights from bert-base-uncased) are loaded, with a random initialized classification head (linear layer) on top. One should fine-tune this head, together with the pre-trained base on a labeled dataset.\n",
    "\n",
    "This is also printed by the warning.\n",
    "\n",
    "We set the `problem_type` to be \"multi_label_classification\", as this will make sure the appropriate loss function is used (namely [`BCEWithLogitsLoss`](https://pytorch.org/docs/stable/generated/torch.nn.BCEWithLogitsLoss.html)). We also make sure the output layer has `len(labels)` output neurons, and we set the id2label and label2id mappings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6XPL1Z_RegBF",
    "outputId": "22994300-8c93-421e-faa4-678d6cc14aab"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file https://huggingface.co/bert-base-uncased/resolve/main/config.json from cache at /home/ec2-user/.cache/huggingface/transformers/3c61d016573b14f7f008c02c4e51a366c67ab274726fe2910691e2a761acf43e.37395cee442ab11005bcd270f3c34464dc1704b715b5d7d52b1a461abe3b9e4e\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"bert-base-uncased\",\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"university\",\n",
      "    \"1\": \"relationships\",\n",
      "    \"2\": \"break ups\",\n",
      "    \"3\": \"divorce\",\n",
      "    \"4\": \"weddings\",\n",
      "    \"5\": \"death\",\n",
      "    \"6\": \"family\",\n",
      "    \"7\": \"friendship\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"label2id\": {\n",
      "    \"break ups\": 2,\n",
      "    \"death\": 5,\n",
      "    \"divorce\": 3,\n",
      "    \"family\": 6,\n",
      "    \"friendship\": 7,\n",
      "    \"relationships\": 1,\n",
      "    \"university\": 0,\n",
      "    \"weddings\": 4\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"problem_type\": \"multi_label_classification\",\n",
      "  \"transformers_version\": \"4.20.1\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading weights file https://huggingface.co/bert-base-uncased/resolve/main/pytorch_model.bin from cache at /home/ec2-user/.cache/huggingface/transformers/a8041bf617d7f94ea26d15e218abd04afc2004805632abc0ed2066aa16d50d04.faf6ea826ae9c5867d12b22257f9877e6b8367890837bd60f7c54a29633f7f2f\n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForSequenceClassification\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"bert-base-uncased\", \n",
    "                                                           problem_type=\"multi_label_classification\", \n",
    "                                                           num_labels=len(labels),\n",
    "                                                           id2label=id2label,\n",
    "                                                           label2id=label2id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mjJGEXShp7te"
   },
   "source": [
    "## Train the model!\n",
    "\n",
    "We are going to train the model using HuggingFace's Trainer API. This requires us to define 2 things: \n",
    "\n",
    "* `TrainingArguments`, which specify training hyperparameters. All options can be found in the [docs](https://huggingface.co/transformers/main_classes/trainer.html#trainingarguments). Below, we for example specify that we want to evaluate after every epoch of training, we would like to save the model every epoch, we set the learning rate, the batch size to use for training/evaluation, how many epochs to train for, and so on.\n",
    "* a `Trainer` object (docs can be found [here](https://huggingface.co/transformers/main_classes/trainer.html#id1))."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "id": "K5a8_vIKqr7P"
   },
   "outputs": [],
   "source": [
    "batch_size = 8\n",
    "metric_name = \"f1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "id": "dR2GmpvDqbuZ"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n"
     ]
    }
   ],
   "source": [
    "from transformers import TrainingArguments, Trainer\n",
    "\n",
    "args = TrainingArguments(\n",
    "    f\"bert-finetuned-sem_eval-english\",\n",
    "    evaluation_strategy = \"epoch\",\n",
    "    save_strategy = \"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=batch_size,\n",
    "    per_device_eval_batch_size=batch_size,\n",
    "    num_train_epochs=5,\n",
    "    weight_decay=0.01,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=metric_name,\n",
    "    #push_to_hub=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1_v2fPFFJ3-v"
   },
   "source": [
    "We are also going to compute metrics while training. For this, we need to define a `compute_metrics` function, that returns a dictionary with the desired metric values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "id": "797b2WHJqUgZ"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score, roc_auc_score, accuracy_score\n",
    "from transformers import EvalPrediction\n",
    "import torch\n",
    "    \n",
    "# source: https://jesusleal.io/2021/04/21/Longformer-multilabel-classification/\n",
    "def multi_label_metrics(predictions, labels, threshold=0.5):\n",
    "    # first, apply sigmoid on predictions which are of shape (batch_size, num_labels)\n",
    "    sigmoid = torch.nn.Sigmoid()\n",
    "    probs = sigmoid(torch.Tensor(predictions))\n",
    "    # next, use threshold to turn them into integer predictions\n",
    "    y_pred = np.zeros(probs.shape)\n",
    "    y_pred[np.where(probs >= threshold)] = 1\n",
    "    # finally, compute metrics\n",
    "    y_true = labels\n",
    "    f1_micro_average = f1_score(y_true=y_true, y_pred=y_pred, average='micro')\n",
    "    roc_auc = roc_auc_score(y_true, y_pred, average = 'micro')\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    # return as dictionary\n",
    "    metrics = {'f1': f1_micro_average,\n",
    "               'roc_auc': roc_auc,\n",
    "               'accuracy': accuracy}\n",
    "    return metrics\n",
    "\n",
    "def compute_metrics(p: EvalPrediction):\n",
    "    preds = p.predictions[0] if isinstance(p.predictions, \n",
    "            tuple) else p.predictions\n",
    "    result = multi_label_metrics(\n",
    "        predictions=preds, \n",
    "        labels=p.label_ids)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fxNo4_TsvzDm"
   },
   "source": [
    "Let's verify a batch as well as a forward pass:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "IlOgGiojuWwG",
    "outputId": "cd0b2c99-b520-468d-8ffc-c36211b7820a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'torch.FloatTensor'"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_dataset['train'][0]['labels'].type()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Y41Kre_jvD7x",
    "outputId": "b6ca888b-6371-40fb-ab83-3dc24d28320a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([  101,  2013,  1996,  2813,  2395,  3485,  1998,  1001,  1015,  9733,\n",
       "         2190, 23836,  2075,  3166,  3310,  1037,  2047, 18932,  2000,  1996,\n",
       "         2630,  4231,  2235,  2237,  7472,  2186,  1012,  1037,  2450,  6026,\n",
       "         2919,  2879,  2007,  1037,  9055,  1998,  7916,  1011,  2004,  1011,\n",
       "         8254,  2868,  2003,  2025,  2112,  1997,  5616,  1521,  1055,  2166,\n",
       "         2933,  1012,  2016,  2333,  2892,  1011,  2406,  2000,  2022,  2485,\n",
       "         2000,  2155,  1998,  2633,  7392,  2091,  1999,  5099, 14756,  1010,\n",
       "         4440,  7685,  1010,  4451,  2100,  2630,  4231,  8815,  1012,  2021,\n",
       "         2043, 15607,  4827,  8088, 23205,  2080,  3065,  2039,  2007,  2010,\n",
       "         5898,  6598,  1010, 14236,  1011, 13721,  2376,  1010,  1998,  1037,\n",
       "         3291,  1010,  2016,  5927,  2498,  2021,  4390,  1012,  2002,  1521,\n",
       "         1055,  2035,  3308,  2005,  5616,  1010,  2021,  2008,  2987,  1521,\n",
       "         1056,  2644,  1996,  8432,  2013, 16018,  2058,   102])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_dataset['train']['input_ids'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sxWcnZ8ku12V",
    "outputId": "26522911-c3cd-466a-ae2d-d81d23003c23"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SequenceClassifierOutput(loss=tensor(0.7572, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), logits=tensor([[ 0.3458,  0.4416,  0.7730, -0.0211, -0.0524,  0.1227,  0.4445, -0.4809]],\n",
       "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#forward pass\n",
    "outputs = model(input_ids=encoded_dataset['train']['input_ids'][0].unsqueeze(0), labels=encoded_dataset['train'][0]['labels'].unsqueeze(0))\n",
    "outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f-X2brZcv0X6"
   },
   "source": [
    "Let's start training!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "id": "chq_3nUz73ib"
   },
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model,\n",
    "    args,\n",
    "    train_dataset=encoded_dataset[\"train\"],\n",
    "    eval_dataset=encoded_dataset[\"validation\"],\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "KXmFds8js6P8",
    "outputId": "66ebb2ab-f93f-48aa-a4dc-36f55f2f8559"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 699\n",
      "  Num Epochs = 5\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 440\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='440' max='440' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [440/440 24:06, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>F1</th>\n",
       "      <th>Roc Auc</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.259024</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.363636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.232916</td>\n",
       "      <td>0.418182</td>\n",
       "      <td>0.635733</td>\n",
       "      <td>0.505051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.214242</td>\n",
       "      <td>0.512000</td>\n",
       "      <td>0.685719</td>\n",
       "      <td>0.545455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.218540</td>\n",
       "      <td>0.403670</td>\n",
       "      <td>0.629709</td>\n",
       "      <td>0.515152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.208285</td>\n",
       "      <td>0.457627</td>\n",
       "      <td>0.657009</td>\n",
       "      <td>0.515152</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 99\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to bert-finetuned-sem_eval-english/checkpoint-88\n",
      "Configuration saved in bert-finetuned-sem_eval-english/checkpoint-88/config.json\n",
      "Model weights saved in bert-finetuned-sem_eval-english/checkpoint-88/pytorch_model.bin\n",
      "tokenizer config file saved in bert-finetuned-sem_eval-english/checkpoint-88/tokenizer_config.json\n",
      "Special tokens file saved in bert-finetuned-sem_eval-english/checkpoint-88/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 99\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to bert-finetuned-sem_eval-english/checkpoint-176\n",
      "Configuration saved in bert-finetuned-sem_eval-english/checkpoint-176/config.json\n",
      "Model weights saved in bert-finetuned-sem_eval-english/checkpoint-176/pytorch_model.bin\n",
      "tokenizer config file saved in bert-finetuned-sem_eval-english/checkpoint-176/tokenizer_config.json\n",
      "Special tokens file saved in bert-finetuned-sem_eval-english/checkpoint-176/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 99\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to bert-finetuned-sem_eval-english/checkpoint-264\n",
      "Configuration saved in bert-finetuned-sem_eval-english/checkpoint-264/config.json\n",
      "Model weights saved in bert-finetuned-sem_eval-english/checkpoint-264/pytorch_model.bin\n",
      "tokenizer config file saved in bert-finetuned-sem_eval-english/checkpoint-264/tokenizer_config.json\n",
      "Special tokens file saved in bert-finetuned-sem_eval-english/checkpoint-264/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 99\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to bert-finetuned-sem_eval-english/checkpoint-352\n",
      "Configuration saved in bert-finetuned-sem_eval-english/checkpoint-352/config.json\n",
      "Model weights saved in bert-finetuned-sem_eval-english/checkpoint-352/pytorch_model.bin\n",
      "tokenizer config file saved in bert-finetuned-sem_eval-english/checkpoint-352/tokenizer_config.json\n",
      "Special tokens file saved in bert-finetuned-sem_eval-english/checkpoint-352/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 99\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to bert-finetuned-sem_eval-english/checkpoint-440\n",
      "Configuration saved in bert-finetuned-sem_eval-english/checkpoint-440/config.json\n",
      "Model weights saved in bert-finetuned-sem_eval-english/checkpoint-440/pytorch_model.bin\n",
      "tokenizer config file saved in bert-finetuned-sem_eval-english/checkpoint-440/tokenizer_config.json\n",
      "Special tokens file saved in bert-finetuned-sem_eval-english/checkpoint-440/special_tokens_map.json\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from bert-finetuned-sem_eval-english/checkpoint-264 (score: 0.512).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=440, training_loss=0.27062329378995026, metrics={'train_runtime': 1449.7065, 'train_samples_per_second': 2.411, 'train_steps_per_second': 0.304, 'total_flos': 229905669335040.0, 'train_loss': 0.27062329378995026, 'epoch': 5.0})"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hiloh9eMK91o"
   },
   "source": [
    "## Evaluate\n",
    "\n",
    "After training, we evaluate our model on the validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 224
    },
    "id": "cMlebJ83LRYG",
    "outputId": "b18102e7-2198-4beb-c874-d39636f740ed"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 99\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='13' max='13' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [13/13 00:09]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.21424183249473572,\n",
       " 'eval_f1': 0.512,\n",
       " 'eval_roc_auc': 0.6857188981596343,\n",
       " 'eval_accuracy': 0.5454545454545454,\n",
       " 'eval_runtime': 10.1389,\n",
       " 'eval_samples_per_second': 9.764,\n",
       " 'eval_steps_per_second': 1.282,\n",
       " 'epoch': 5.0}"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.evaluate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3nmvJp0pLq-3"
   },
   "source": [
    "## Inference\n",
    "\n",
    "Let's test the model on a new sentence:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "BFT_test_val_results = pd.read_csv('dataset_bert_test_val.csv')\n",
    "BFT_test_val_results['description'] = BFT_test_val_results['description'].apply(lambda x: re.sub(r'[^a-zA-Z ]+', '', x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'When tragedy strikes Michele Windsors family she is forced to move from Los Angeles to New York City to live with the wealthy aristocratic grandparents she has never met In their historic Fifth Avenue mansion filled with a centurys worth of family secrets Michele discovers the biggest family secret of all  an ancestors diary that amazingly has the power to send her back in time to  the year it was written There at a glamorous highsociety masquerade ball Michele meets the young man with striking blue eyes who has haunted her dreams all her life And she finds herself falling for him and into an otherworldly romanceSoon Michele is leading a double life struggling to balance her contemporary high school world with her escapes into the past But when she stumbles upon a terrible discovery she is propelled on a race through history to save the boy she loves  and to complete a quest that will determine their fate'"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BFT_test_val_results['description'][293]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 torch.Size([1, 8])\n",
      "1 torch.Size([1, 8])\n",
      "2 torch.Size([1, 8])\n",
      "3 torch.Size([1, 8])\n",
      "4 torch.Size([1, 8])\n",
      "5 torch.Size([1, 8])\n",
      "6 torch.Size([1, 8])\n",
      "7 torch.Size([1, 8])\n",
      "8 torch.Size([1, 8])\n",
      "9 torch.Size([1, 8])\n",
      "10 torch.Size([1, 8])\n",
      "11 torch.Size([1, 8])\n",
      "12 torch.Size([1, 8])\n",
      "13 torch.Size([1, 8])\n",
      "14 torch.Size([1, 8])\n",
      "15 torch.Size([1, 8])\n",
      "16 torch.Size([1, 8])\n",
      "17 torch.Size([1, 8])\n",
      "18 torch.Size([1, 8])\n",
      "19 torch.Size([1, 8])\n",
      "20 torch.Size([1, 8])\n",
      "21 torch.Size([1, 8])\n",
      "22 torch.Size([1, 8])\n",
      "23 torch.Size([1, 8])\n",
      "24 torch.Size([1, 8])\n",
      "25 torch.Size([1, 8])\n",
      "26 torch.Size([1, 8])\n",
      "27 torch.Size([1, 8])\n",
      "28 torch.Size([1, 8])\n",
      "29 torch.Size([1, 8])\n",
      "30 torch.Size([1, 8])\n",
      "31 torch.Size([1, 8])\n",
      "32 torch.Size([1, 8])\n",
      "33 torch.Size([1, 8])\n",
      "34 torch.Size([1, 8])\n",
      "35 torch.Size([1, 8])\n",
      "36 torch.Size([1, 8])\n",
      "37 torch.Size([1, 8])\n",
      "38 torch.Size([1, 8])\n",
      "39 torch.Size([1, 8])\n",
      "40 torch.Size([1, 8])\n",
      "41 torch.Size([1, 8])\n",
      "42 torch.Size([1, 8])\n",
      "43 torch.Size([1, 8])\n",
      "44 torch.Size([1, 8])\n",
      "45 torch.Size([1, 8])\n",
      "46 torch.Size([1, 8])\n",
      "47 torch.Size([1, 8])\n",
      "48 torch.Size([1, 8])\n",
      "49 torch.Size([1, 8])\n",
      "50 torch.Size([1, 8])\n",
      "51 torch.Size([1, 8])\n",
      "52 torch.Size([1, 8])\n",
      "53 torch.Size([1, 8])\n",
      "54 torch.Size([1, 8])\n",
      "55 torch.Size([1, 8])\n",
      "56 torch.Size([1, 8])\n",
      "57 torch.Size([1, 8])\n",
      "58 torch.Size([1, 8])\n",
      "59 torch.Size([1, 8])\n",
      "60 torch.Size([1, 8])\n",
      "61 torch.Size([1, 8])\n",
      "62 torch.Size([1, 8])\n",
      "63 torch.Size([1, 8])\n",
      "64 torch.Size([1, 8])\n",
      "65 torch.Size([1, 8])\n",
      "66 torch.Size([1, 8])\n",
      "67 torch.Size([1, 8])\n",
      "68 torch.Size([1, 8])\n",
      "69 torch.Size([1, 8])\n",
      "70 torch.Size([1, 8])\n",
      "71 torch.Size([1, 8])\n",
      "72 torch.Size([1, 8])\n",
      "73 torch.Size([1, 8])\n",
      "74 torch.Size([1, 8])\n",
      "75 torch.Size([1, 8])\n",
      "76 torch.Size([1, 8])\n",
      "77 torch.Size([1, 8])\n",
      "78 torch.Size([1, 8])\n",
      "79 torch.Size([1, 8])\n",
      "80 torch.Size([1, 8])\n",
      "81 torch.Size([1, 8])\n",
      "82 torch.Size([1, 8])\n",
      "83 torch.Size([1, 8])\n",
      "84 torch.Size([1, 8])\n",
      "85 torch.Size([1, 8])\n",
      "86 torch.Size([1, 8])\n",
      "87 torch.Size([1, 8])\n",
      "88 torch.Size([1, 8])\n",
      "89 torch.Size([1, 8])\n",
      "90 torch.Size([1, 8])\n",
      "91 torch.Size([1, 8])\n",
      "92 torch.Size([1, 8])\n",
      "93 torch.Size([1, 8])\n",
      "94 torch.Size([1, 8])\n",
      "95 torch.Size([1, 8])\n",
      "96 torch.Size([1, 8])\n",
      "97 torch.Size([1, 8])\n",
      "98 torch.Size([1, 8])\n",
      "99 torch.Size([1, 8])\n",
      "100 torch.Size([1, 8])\n",
      "101 torch.Size([1, 8])\n",
      "102 torch.Size([1, 8])\n",
      "103 torch.Size([1, 8])\n",
      "104 torch.Size([1, 8])\n",
      "105 torch.Size([1, 8])\n",
      "106 torch.Size([1, 8])\n",
      "107 torch.Size([1, 8])\n",
      "108 torch.Size([1, 8])\n",
      "109 torch.Size([1, 8])\n",
      "110 torch.Size([1, 8])\n",
      "111 torch.Size([1, 8])\n",
      "112 torch.Size([1, 8])\n",
      "113 torch.Size([1, 8])\n",
      "114 torch.Size([1, 8])\n",
      "115 torch.Size([1, 8])\n",
      "116 torch.Size([1, 8])\n",
      "117 torch.Size([1, 8])\n",
      "118 torch.Size([1, 8])\n",
      "119 torch.Size([1, 8])\n",
      "120 torch.Size([1, 8])\n",
      "121 torch.Size([1, 8])\n",
      "122 torch.Size([1, 8])\n",
      "123 torch.Size([1, 8])\n",
      "124 torch.Size([1, 8])\n",
      "125 torch.Size([1, 8])\n",
      "126 torch.Size([1, 8])\n",
      "127 torch.Size([1, 8])\n",
      "128 torch.Size([1, 8])\n",
      "129 torch.Size([1, 8])\n",
      "130 torch.Size([1, 8])\n",
      "131 torch.Size([1, 8])\n",
      "132 torch.Size([1, 8])\n",
      "133 torch.Size([1, 8])\n",
      "134 torch.Size([1, 8])\n",
      "135 torch.Size([1, 8])\n",
      "136 torch.Size([1, 8])\n",
      "137 torch.Size([1, 8])\n",
      "138 torch.Size([1, 8])\n",
      "139 torch.Size([1, 8])\n",
      "140 torch.Size([1, 8])\n",
      "141 torch.Size([1, 8])\n",
      "142 torch.Size([1, 8])\n",
      "143 torch.Size([1, 8])\n",
      "144 torch.Size([1, 8])\n",
      "145 torch.Size([1, 8])\n",
      "146 torch.Size([1, 8])\n",
      "147 torch.Size([1, 8])\n",
      "148 torch.Size([1, 8])\n",
      "149 torch.Size([1, 8])\n",
      "150 torch.Size([1, 8])\n",
      "151 torch.Size([1, 8])\n",
      "152 torch.Size([1, 8])\n",
      "153 torch.Size([1, 8])\n",
      "154 torch.Size([1, 8])\n",
      "155 torch.Size([1, 8])\n",
      "156 torch.Size([1, 8])\n",
      "157 torch.Size([1, 8])\n",
      "158 torch.Size([1, 8])\n",
      "159 torch.Size([1, 8])\n",
      "160 torch.Size([1, 8])\n",
      "161 torch.Size([1, 8])\n",
      "162 torch.Size([1, 8])\n",
      "163 torch.Size([1, 8])\n",
      "164 torch.Size([1, 8])\n",
      "165 torch.Size([1, 8])\n",
      "166 torch.Size([1, 8])\n",
      "167 torch.Size([1, 8])\n",
      "168 torch.Size([1, 8])\n",
      "169 torch.Size([1, 8])\n",
      "170 torch.Size([1, 8])\n",
      "171 torch.Size([1, 8])\n",
      "172 torch.Size([1, 8])\n",
      "173 torch.Size([1, 8])\n",
      "174 torch.Size([1, 8])\n",
      "175 torch.Size([1, 8])\n",
      "176 torch.Size([1, 8])\n",
      "177 torch.Size([1, 8])\n",
      "178 torch.Size([1, 8])\n",
      "179 torch.Size([1, 8])\n",
      "180 torch.Size([1, 8])\n",
      "181 torch.Size([1, 8])\n",
      "182 torch.Size([1, 8])\n",
      "183 torch.Size([1, 8])\n",
      "184 torch.Size([1, 8])\n",
      "185 torch.Size([1, 8])\n",
      "186 torch.Size([1, 8])\n",
      "187 torch.Size([1, 8])\n",
      "188 torch.Size([1, 8])\n",
      "189 torch.Size([1, 8])\n",
      "190 torch.Size([1, 8])\n",
      "191 torch.Size([1, 8])\n",
      "192 torch.Size([1, 8])\n",
      "193 torch.Size([1, 8])\n",
      "194 torch.Size([1, 8])\n",
      "195 torch.Size([1, 8])\n",
      "196 torch.Size([1, 8])\n",
      "197 torch.Size([1, 8])\n",
      "198 torch.Size([1, 8])\n",
      "199 torch.Size([1, 8])\n",
      "200 torch.Size([1, 8])\n",
      "201 torch.Size([1, 8])\n",
      "202 torch.Size([1, 8])\n",
      "203 torch.Size([1, 8])\n",
      "204 torch.Size([1, 8])\n",
      "205 torch.Size([1, 8])\n",
      "206 torch.Size([1, 8])\n",
      "207 torch.Size([1, 8])\n",
      "208 torch.Size([1, 8])\n",
      "209 torch.Size([1, 8])\n",
      "210 torch.Size([1, 8])\n",
      "211 torch.Size([1, 8])\n",
      "212 torch.Size([1, 8])\n",
      "213 torch.Size([1, 8])\n",
      "214 torch.Size([1, 8])\n",
      "215 torch.Size([1, 8])\n",
      "216 torch.Size([1, 8])\n",
      "217 torch.Size([1, 8])\n",
      "218 torch.Size([1, 8])\n",
      "219 torch.Size([1, 8])\n",
      "220 torch.Size([1, 8])\n",
      "221 torch.Size([1, 8])\n",
      "222 torch.Size([1, 8])\n",
      "223 torch.Size([1, 8])\n",
      "224 torch.Size([1, 8])\n",
      "225 torch.Size([1, 8])\n",
      "226 torch.Size([1, 8])\n",
      "227 torch.Size([1, 8])\n",
      "228 torch.Size([1, 8])\n",
      "229 torch.Size([1, 8])\n",
      "230 torch.Size([1, 8])\n",
      "231 torch.Size([1, 8])\n",
      "232 torch.Size([1, 8])\n",
      "233 torch.Size([1, 8])\n",
      "234 torch.Size([1, 8])\n",
      "235 torch.Size([1, 8])\n",
      "236 torch.Size([1, 8])\n",
      "237 torch.Size([1, 8])\n",
      "238 torch.Size([1, 8])\n",
      "239 torch.Size([1, 8])\n",
      "240 torch.Size([1, 8])\n",
      "241 torch.Size([1, 8])\n",
      "242 torch.Size([1, 8])\n",
      "243 torch.Size([1, 8])\n",
      "244 torch.Size([1, 8])\n",
      "245 torch.Size([1, 8])\n",
      "246 torch.Size([1, 8])\n",
      "247 torch.Size([1, 8])\n",
      "248 torch.Size([1, 8])\n",
      "249 torch.Size([1, 8])\n",
      "250 torch.Size([1, 8])\n",
      "251 torch.Size([1, 8])\n",
      "252 torch.Size([1, 8])\n",
      "253 torch.Size([1, 8])\n",
      "254 torch.Size([1, 8])\n",
      "255 torch.Size([1, 8])\n",
      "256 torch.Size([1, 8])\n",
      "257 torch.Size([1, 8])\n",
      "258 torch.Size([1, 8])\n",
      "259 torch.Size([1, 8])\n",
      "260 torch.Size([1, 8])\n",
      "261 torch.Size([1, 8])\n",
      "262 torch.Size([1, 8])\n",
      "263 torch.Size([1, 8])\n",
      "264 torch.Size([1, 8])\n",
      "265 torch.Size([1, 8])\n",
      "266 torch.Size([1, 8])\n",
      "267 torch.Size([1, 8])\n",
      "268 torch.Size([1, 8])\n",
      "269 torch.Size([1, 8])\n",
      "270 torch.Size([1, 8])\n",
      "271 torch.Size([1, 8])\n",
      "272 torch.Size([1, 8])\n",
      "273 torch.Size([1, 8])\n",
      "274 torch.Size([1, 8])\n",
      "275 torch.Size([1, 8])\n",
      "276 torch.Size([1, 8])\n",
      "277 torch.Size([1, 8])\n",
      "278 torch.Size([1, 8])\n",
      "279 torch.Size([1, 8])\n",
      "280 torch.Size([1, 8])\n",
      "281 torch.Size([1, 8])\n",
      "282 torch.Size([1, 8])\n",
      "283 torch.Size([1, 8])\n",
      "284 torch.Size([1, 8])\n",
      "285 torch.Size([1, 8])\n",
      "286 torch.Size([1, 8])\n",
      "287 torch.Size([1, 8])\n",
      "288 torch.Size([1, 8])\n",
      "289 torch.Size([1, 8])\n",
      "290 torch.Size([1, 8])\n",
      "291 torch.Size([1, 8])\n",
      "292 torch.Size([1, 8])\n",
      "293 torch.Size([1, 8])\n",
      "294 torch.Size([1, 8])\n",
      "295 torch.Size([1, 8])\n",
      "296 torch.Size([1, 8])\n",
      "297 torch.Size([1, 8])\n",
      "298 torch.Size([1, 8])\n"
     ]
    }
   ],
   "source": [
    "test_probabilities = []\n",
    "for i in range(0,len(BFT_test_val_results)):\n",
    "    text = BFT_test_val_results['description'][i]\n",
    "    encoding = tokenizer(text, return_tensors=\"pt\", padding=\"max_length\", truncation=True, max_length=128)\n",
    "    encoding = {k: v.to(trainer.model.device) for k,v in encoding.items()}\n",
    "    outputs = trainer.model(**encoding)\n",
    "    logits = outputs.logits\n",
    "    print(i, logits.shape)\n",
    "    # apply sigmoid + threshold\n",
    "    sigmoid = torch.nn.Sigmoid()\n",
    "    probs = sigmoid(logits.squeeze().cpu())\n",
    "    test_probabilities.append(probs.tolist())\n",
    "    #predictions = np.zeros(probs.shape)\n",
    "    #predictions[np.where(probs >= 0.5)] = 1\n",
    "# turn predicted id's into actual label names\n",
    "    #predicted_labels = [id2label[idx] for idx, label in enumerate(predictions) if label == 1.0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "BFT_test_val_results['scores'] = test_probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "BFT_test_val_results.to_csv('bert_finetuned_test_val_results_2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "id": "3fxjfr8PLD42"
   },
   "outputs": [],
   "source": [
    "#text = \"I'm happy I can finally train a model for multi-label classification\"\n",
    "text = dataset['test'][0]['description']\n",
    "encoding = tokenizer(text, return_tensors=\"pt\")\n",
    "encoding = {k: v.to(trainer.model.device) for k,v in encoding.items()}\n",
    "\n",
    "outputs = trainer.model(**encoding)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8THm5-XgNHPm"
   },
   "source": [
    "The logits that come out of the model are of shape (batch_size, num_labels). As we are only forwarding a single sentence through the model, the `batch_size` equals 1. The logits is a tensor that contains the (unnormalized) scores for every individual label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KOBosj4UL2tU",
    "outputId": "be370f49-3840-4c76-b193-76083e49701e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 8])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits = outputs.logits\n",
    "logits.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DC4XdDaHNVcd"
   },
   "source": [
    "To turn them into actual predicted labels, we first apply a sigmoid function independently to every score, such that every score is turned into a number between 0 and 1, that can be interpreted as a \"probability\" for how certain the model is that a given class belongs to the input text.\n",
    "\n",
    "Next, we use a threshold (typically, 0.5) to turn every probability into either a 1 (which means, we predict the label for the given example) or a 0 (which means, we don't predict the label for the given example)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mEkAQleMMT0k",
    "outputId": "fddb51cb-bf01-420a-fd5b-4a7c2e775446"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.04387282207608223, 0.8390726447105408, 0.04064767807722092, 0.03451037406921387, 0.06476005911827087, 0.07106984406709671, 0.18297196924686432, 0.25362786650657654]\n",
      "['relationships']\n"
     ]
    }
   ],
   "source": [
    "# apply sigmoid + threshold\n",
    "sigmoid = torch.nn.Sigmoid()\n",
    "probs = sigmoid(logits.squeeze().cpu())\n",
    "print(probs.tolist())\n",
    "predictions = np.zeros(probs.shape)\n",
    "predictions[np.where(probs >= 0.5)] = 1\n",
    "# turn predicted id's into actual label names\n",
    "predicted_labels = [id2label[idx] for idx, label in enumerate(predictions) if label == 1.0]\n",
    "print(predicted_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "['university',\n",
    " 'relationships',\n",
    " 'break ups',\n",
    " 'divorce',\n",
    " 'weddings',\n",
    " 'death',\n",
    " 'family',\n",
    " 'friendship']"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Fine-tuning BERT (and friends) for multi-label text classification.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "091f8220f33241f288faa0612853585f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_6111a73e684a47769bda7183a836ee91",
      "max": 3,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_8b1899a0c4b144d7a5e6599f8afb8b65",
      "value": 3
     }
    },
    "1045bb16e3694410898a73cf1b848917": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_bbba60f793c14100934a268063f63d26",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_cd3570ddf67541d7818d97e236c54e54",
      "value": " 3/3 [00:00&lt;00:00, 75.93it/s]"
     }
    },
    "308fa6a7348140ec981a8d6c7d31f346": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5080d322a8034924b652b379c04667ed": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6111a73e684a47769bda7183a836ee91": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8b1899a0c4b144d7a5e6599f8afb8b65": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "8bc92587e35443488445e7521fbd0a13": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_5080d322a8034924b652b379c04667ed",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_cb95e545fbdd4e99903bf634df694c9f",
      "value": "100%"
     }
    },
    "9a1aa9f2cc29473f9f8e5459d2641e76": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_8bc92587e35443488445e7521fbd0a13",
       "IPY_MODEL_091f8220f33241f288faa0612853585f",
       "IPY_MODEL_1045bb16e3694410898a73cf1b848917"
      ],
      "layout": "IPY_MODEL_308fa6a7348140ec981a8d6c7d31f346"
     }
    },
    "bbba60f793c14100934a268063f63d26": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "cb95e545fbdd4e99903bf634df694c9f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "cd3570ddf67541d7818d97e236c54e54": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
