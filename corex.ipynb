{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "560702f2-5390-4824-861a-cc573ae41e9b",
   "metadata": {},
   "source": [
    "# Corex\n",
    "code: https://github.com/gregversteeg/corex_topic/blob/master/corextopic/example/corex_topic_example.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "17e15bb1-657f-4c69-bb1d-2716eba090e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "import scipy.sparse as ss\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "import corextopic.corextopic as ct\n",
    "import corextopic.vis_topic as vt # jupyter notebooks will complain matplotlib is being loaded twice\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.corpus import wordnet\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3ebe569-be5a-4238-a801-ce77fade4c24",
   "metadata": {},
   "source": [
    "## Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b4d773ef-dc12-4457-8c5f-02c7300ca1ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenized Text DF Size: 29652\n"
     ]
    }
   ],
   "source": [
    "#import data\n",
    "model_data = pd.read_csv('s3://book-data-ucb-capstone-s2022/tokenized_data.csv')\n",
    "print('Tokenized Text DF Size:', len(model_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d28544a5-364d-445c-963b-4bde8c2748a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#preprocessing\n",
    "def preprocess_text(text):\n",
    "\n",
    "  #lowercase text\n",
    "  text_preprocessed = text.lower()\n",
    "  #remove punctuation\n",
    "  text_preprocessed = re.sub(r'[^a-zA-Z ]+', '', text_preprocessed)\n",
    "  #tokenize for stopword removal\n",
    "  text_preprocessed = word_tokenize(text_preprocessed)\n",
    "  #remove stopwords\n",
    "  text_preprocessed = [word for word in text_preprocessed if word not in stopwords.words('english')]\n",
    "  #join to make string again\n",
    "  #text_preprocessed = (\" \").join(text_preprocessed)\n",
    "\n",
    "  return text_preprocessed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4f02b374-ffcc-4a20-a7fb-64ac2d94f6be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5min 16s, sys: 22.8 s, total: 5min 39s\n",
      "Wall time: 5min 39s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "model_data['tokens'] = model_data['description'].apply(lambda x: preprocess_text(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ff22b543-6416-46ba-8f4e-906227526950",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_data['liststring'] = [','.join(map(str, l)) for l in model_data['tokens']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3dcfaf7-12fc-4ca5-a0c8-b3bdf300e2f4",
   "metadata": {},
   "source": [
    "## Create Synsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5ac1a761-571d-44ae-ad8d-89ceef199303",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_synsets(event):\n",
    "  \n",
    "  synonym = [] \n",
    "    \n",
    "  for synset in wordnet.synsets(event): \n",
    "      for i in synset.lemmas(): \n",
    "          synonym.append(i.name()) # add all the synonyms available \n",
    "    \n",
    "  return synonym"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9bccf4c2-5e25-42af-ab10-39be0a12f9f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>life_event</th>\n",
       "      <th>synsets</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>university</td>\n",
       "      <td>[college, university, campus, academia, profes...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>relationships</td>\n",
       "      <td>[go steady, go out, date, relationship, kinshi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>break ups</td>\n",
       "      <td>[breakup, break up, split up, broken up, dumpe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>divorce</td>\n",
       "      <td>[divorce, divorced, divorces]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>wedding</td>\n",
       "      <td>[wedding, wedding ceremony, nuptials, hymeneal...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>death</td>\n",
       "      <td>[death, decease, deceased, dying]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>family</td>\n",
       "      <td>[family, mother, father, brother, sister, mom,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>friendship</td>\n",
       "      <td>[friends, friend, friendship, friendships]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      life_event                                            synsets\n",
       "0     university  [college, university, campus, academia, profes...\n",
       "1  relationships  [go steady, go out, date, relationship, kinshi...\n",
       "2      break ups  [breakup, break up, split up, broken up, dumpe...\n",
       "3        divorce                      [divorce, divorced, divorces]\n",
       "4        wedding  [wedding, wedding ceremony, nuptials, hymeneal...\n",
       "5          death                  [death, decease, deceased, dying]\n",
       "6         family  [family, mother, father, brother, sister, mom,...\n",
       "7     friendship         [friends, friend, friendship, friendships]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#creating library dataframe\n",
    "\n",
    "#creating library dataframe\n",
    "\n",
    "\n",
    "life_events = ['university', 'relationships', 'break ups', 'divorce', 'wedding', \n",
    "               'death', 'family', 'friendship']\n",
    "\n",
    "#create synsets for select events where decent synsets exist\n",
    "relationship_list = create_synsets('go_steady') + ['relationship', 'kinship', 'romance', 'dating']\n",
    "marriage_list = create_synsets('marriage')\n",
    "wedding_list = create_synsets('wedding') + ['matrimony']\n",
    "\n",
    "#replace underscore (_) with space\n",
    "relationship_list = [i.replace(\"_\", \" \") for i in relationship_list]\n",
    "marriage_list = [i.replace(\"_\", \" \") for i in marriage_list]\n",
    "wedding_list = [i.replace(\"_\", \" \") for i in wedding_list]\n",
    "\n",
    "#remove certain words\n",
    "wedding_list.remove('tie')\n",
    "wedding_list.remove('marriage')\n",
    "relationship_list.remove('see')\n",
    "\n",
    "synsets = [['college', 'university', 'campus', 'academia', 'professor', 'colleges', 'universities', 'professors'], \n",
    "           relationship_list, \n",
    "           ['breakup', 'break up', 'split up', 'broken up', 'dumped', 'breaks up', 'splits up', 'dumps', 'dump', 'breaks off', 'break off'], \n",
    "           ['divorce', 'divorced', 'divorces'], \n",
    "           wedding_list,  \n",
    "           ['death', 'decease', 'deceased', 'dying'],\n",
    "           ['family', 'mother', 'father', 'brother', 'sister', 'mom', 'dad'],\n",
    "           ['friends', 'friend', 'friendship', 'friendships']]\n",
    "           #marriage_list]\n",
    "\n",
    "# Create the pandas DataFrame with column name is provided explicitly\n",
    "df_lib = pd.DataFrame(life_events, columns=['life_event'])\n",
    "df_lib['synsets'] = synsets\n",
    " \n",
    "# print dataframe.\n",
    "df_lib"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61bfb278-d294-413f-8f16-cbb929317a56",
   "metadata": {},
   "source": [
    "## Corex Topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "378fd2d2-7f22-4aa9-8181-6c79fb8dcb7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(29652, 20000)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Transform data into a sparse matrix\n",
    "vectorizer = CountVectorizer(stop_words='english', max_features=20000, binary=True, ngram_range=(1,2))\n",
    "doc_word = vectorizer.fit_transform(model_data.liststring)\n",
    "doc_word = ss.csr_matrix(doc_word)\n",
    "\n",
    "doc_word.shape # n_docs x m_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fec1a225-cb41-47da-8ac8-adb842bd612e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/lib/python3.9/site-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "# Get words that label the columns (needed to extract readable topics and make anchoring easier)\n",
    "words = list(np.asarray(vectorizer.get_feature_names()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "684bb284-c8de-4cb0-bde0-466b43b6e696",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: Anchor word not in word column labels provided to CorEx: academia\n",
      "WARNING: Anchor word not in word column labels provided to CorEx: universities\n",
      "WARNING: Anchor word not in word column labels provided to CorEx: go steady\n",
      "WARNING: Anchor word not in word column labels provided to CorEx: go out\n",
      "WARNING: Anchor word not in word column labels provided to CorEx: break up\n",
      "WARNING: Anchor word not in word column labels provided to CorEx: split up\n",
      "WARNING: Anchor word not in word column labels provided to CorEx: broken up\n",
      "WARNING: Anchor word not in word column labels provided to CorEx: breaks up\n",
      "WARNING: Anchor word not in word column labels provided to CorEx: splits up\n",
      "WARNING: Anchor word not in word column labels provided to CorEx: breaks off\n",
      "WARNING: Anchor word not in word column labels provided to CorEx: break off\n",
      "WARNING: Anchor word not in word column labels provided to CorEx: divorces\n",
      "WARNING: Anchor word not in word column labels provided to CorEx: wedding ceremony\n",
      "WARNING: Anchor word not in word column labels provided to CorEx: hymeneals\n",
      "WARNING: Anchor word not in word column labels provided to CorEx: marriage ceremony\n",
      "WARNING: Anchor word not in word column labels provided to CorEx: wedding party\n",
      "WARNING: Anchor word not in word column labels provided to CorEx: get married\n",
      "WARNING: Anchor word not in word column labels provided to CorEx: conjoin\n",
      "WARNING: Anchor word not in word column labels provided to CorEx: hook up with\n",
      "WARNING: Anchor word not in word column labels provided to CorEx: get hitched with\n",
      "WARNING: Anchor word not in word column labels provided to CorEx: espouse\n",
      "WARNING: Anchor word not in word column labels provided to CorEx: splice\n",
      "WARNING: Anchor word not in word column labels provided to CorEx: matrimony\n",
      "WARNING: Anchor word not in word column labels provided to CorEx: decease\n"
     ]
    }
   ],
   "source": [
    "#anchor words\n",
    "# Anchor 'nasa' and 'space' to first topic, 'sports' and 'stadium' to second topic, so on...\n",
    "anchor_words = synsets\n",
    "\n",
    "anchored_topic_model = ct.Corex(n_hidden=8, seed=2)\n",
    "anchored_topic_model.fit(doc_word, words=words, anchors=anchor_words, anchor_strength=6);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "03f8d1fb-1791-4af8-a925-2515a28bd14b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: college, university, professor, murder, killer, campus, detective, case, police, crime\n",
      "1: romance, relationship, new york, york, date, york times, dating, times bestselling, times, bestselling\n",
      "2: novel, story, characters, fiction, stories, readers, american, literary, classic, written\n",
      "3: shes, hes, doesnt, school, divorce, like, going, isnt, things, theres\n",
      "4: marry, wedding, love, life, woman, heart, past, wed, man, years\n",
      "5: death, dying, ancient, evil, power, world, battle, save, deceased, war\n",
      "6: family, father, mother, brother, sister, dad, mom, older, younger, mothers\n",
      "7: friends, friend, friendship, best friend, friendships, best, best friends, new friends, old friend, family friends\n"
     ]
    }
   ],
   "source": [
    "for n in range(len(anchor_words)):\n",
    "    topic_words,_,_ = zip(*anchored_topic_model.get_topics(topic=n))\n",
    "    print('{}: '.format(n) + ', '.join(topic_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f9fdbe28-801e-4101-9ac4-2953d92b1d3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(29652, 8)\n"
     ]
    }
   ],
   "source": [
    "print(anchored_topic_model.labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3c25992c-720d-483b-87d2-5be0f6c63506",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[False False False False  True  True False False]\n",
      " [False False False  True False  True False  True]\n",
      " [False False  True False False False False False]\n",
      " [False  True  True False False False False False]\n",
      " [False False False False False False False False]\n",
      " [False False  True False  True  True  True False]\n",
      " [False False  True False False False False False]\n",
      " [False False  True False False  True False False]\n",
      " [False False  True False False  True False False]\n",
      " [False False False False False False False False]]\n"
     ]
    }
   ],
   "source": [
    "print(anchored_topic_model.labels[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0108b06f-2b41-4818-a21e-7dd9ad02315c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.30952189e-04 2.00749196e-05 8.20213684e-06 4.24435024e-02\n",
      "  8.62059347e-01 9.99999000e-01 1.48496407e-06 1.98047821e-05]\n",
      " [3.08545721e-03 4.42700711e-04 1.09199225e-06 7.81038022e-01\n",
      "  2.08020471e-03 8.01490132e-01 1.19204393e-06 9.99999000e-01]\n",
      " [1.82770177e-05 2.09823777e-04 9.99999000e-01 1.73319490e-06\n",
      "  6.87926195e-02 1.00000000e-06 1.46244360e-05 7.15620585e-06]\n",
      " [2.59722232e-06 9.99999000e-01 9.99999000e-01 1.00000000e-06\n",
      "  3.12337559e-04 1.38263755e-06 1.27813624e-05 6.97182965e-06]\n",
      " [2.59763771e-06 1.84193587e-05 1.00000000e-06 6.43320361e-04\n",
      "  5.51390417e-05 1.00000000e-06 2.90482642e-06 7.10561609e-06]\n",
      " [8.42233936e-06 6.41905813e-03 9.99999000e-01 1.25675410e-06\n",
      "  9.98863277e-01 9.99999000e-01 9.99999000e-01 6.96088897e-06]\n",
      " [1.70090214e-04 7.73729462e-05 9.99999000e-01 1.00000000e-06\n",
      "  1.68550454e-06 4.07162672e-04 6.79327148e-05 1.00000000e-06]\n",
      " [2.64699858e-06 1.94959923e-05 9.99999000e-01 1.32745474e-05\n",
      "  8.92052557e-06 9.89343319e-01 2.90118633e-06 7.07703870e-06]\n",
      " [6.77523978e-06 8.04591783e-04 9.99999000e-01 1.00000000e-06\n",
      "  1.43708212e-04 9.60657526e-01 2.89280293e-06 7.04046995e-06]\n",
      " [2.83024576e-06 1.83956015e-05 1.00000000e-06 1.27718225e-05\n",
      "  1.04043516e-05 8.97969933e-06 2.91328319e-06 7.07337106e-06]]\n"
     ]
    }
   ],
   "source": [
    "print(anchored_topic_model.p_y_given_x[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6dce5b06-3575-4c8d-9cd1-549b8bdd409a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results = pd.DataFrame(anchored_topic_model.p_y_given_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ae61e584-8ff9-48a1-ac5b-8c56e8e307bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results.columns = ['university', 'relationships', 'break ups', 'divorce', 'wedding', \n",
    "               'death', 'family', 'friendship']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f0b19b5-9a9e-4793-b4ec-ed47b686f96a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
